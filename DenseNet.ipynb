{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\bvcha\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "#Matplot Images\n",
    "import matplotlib.image as mpimg\n",
    "# Tensflor and Keras Layer and Model and Optimize and Loss\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import *\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "#PreTrained Model\n",
    "from tensorflow.keras.applications import *\n",
    "#Image Generator DataAugmentation\n",
    "#Early Stopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# Warnings Remove \n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#Splitting Data \n",
    "# import splitfolders\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import random\n",
    "from sklearn.cluster import KMeans\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"C:\\\\Users\\\\bvcha\\\\Desktop\\\\Senior Design Project\\\\Datasets\\\\PaddyDoctor\\\\Paddy_doctor\\\\train_images_paddy\"\n",
    "\n",
    "filepath =[]\n",
    "label = []\n",
    "\n",
    "folds = os.listdir(directory)\n",
    "\n",
    "for fold in folds:\n",
    "    f_path = os.path.join(directory , fold)\n",
    "    \n",
    "    imgs = os.listdir(f_path)\n",
    "    \n",
    "    for img in imgs:\n",
    "        \n",
    "        img_path = os.path.join(f_path , img)\n",
    "        filepath.append(img_path)\n",
    "        label.append(fold)\n",
    "        \n",
    "#Concat data paths with labels\n",
    "file_path_series = pd.Series(filepath , name= 'filepath')\n",
    "Label_path_series = pd.Series(label , name = 'label')\n",
    "df_train = pd.concat([file_path_series ,Label_path_series ] , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn. model_selection import train_test_split\n",
    "train_df , val_df = train_test_split(df_train ,train_size = 0.9 , shuffle = True ,random_state = 42 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Images:\n",
      "Found 10407 files belonging to 10 classes.\n",
      "Using 6245 files for training.\n",
      "Validation Images:\n",
      "Found 10407 files belonging to 10 classes.\n",
      "Using 4162 files for validation.\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'C:\\\\Users\\\\bvcha\\\\Desktop\\\\Senior Design Project\\\\Datasets\\\\PaddyDoctor\\\\Paddy_doctor\\\\train_images_paddy'\n",
    "\n",
    "print('Training Images:')\n",
    "# creating the training dataset\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.4,\n",
    "    subset='training',\n",
    "    seed=123,\n",
    "    image_size=(256, 256),\n",
    "    batch_size=128)\n",
    "\n",
    "#Testing Augmented Data\n",
    "print('Validation Images:')\n",
    "validation_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir, \n",
    "    validation_split=0.4,\n",
    "    subset='validation',\n",
    "    seed=123,\n",
    "    image_size=(256, 256),\n",
    "    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3469 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory = 'C:\\\\Users\\\\bvcha\\\\Desktop\\\\Senior Design Project\\\\Datasets\\\\PaddyDoctor\\\\Paddy_doctor\\\\test_images_paddy',\n",
    "    batch_size = 128,\n",
    "    image_size = (256, 256),\n",
    "    label_mode = None,\n",
    "    shuffle=False\n",
    ")\n",
    "test_ds = validation_ds.map(lambda x, y: (x / 255.0, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(lambda x, y: (x / 255.0, y))\n",
    "# Val Data\n",
    "validation_ds = validation_ds.map(lambda x, y: (x / 255.0, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\bvcha\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\bvcha\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "29084464/29084464 [==============================] - 5s 0us/step\n"
     ]
    }
   ],
   "source": [
    "DenseNet121_base = DenseNet121(weights='imagenet',\n",
    "                                    include_top=False, \n",
    "                                   input_shape=(256, 256, 3),\n",
    "                                     pooling = 'avg'\n",
    "                                   )\n",
    "\n",
    "# Freeze the pre-trained base model layers\n",
    "DenseNet121_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\bvcha\\anaconda3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet121 (Functional)    (None, 1024)              7037504   \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 1024)              4096      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 220)               225500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 220)               48620     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 220)               48620     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 220)               48620     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 220)               48620     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 220)               48620     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 220)               48620     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 220)               48620     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 220)               48620     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 220)               48620     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 220)               48620     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                2210      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7755510 (29.58 MB)\n",
      "Trainable params: 715958 (2.73 MB)\n",
      "Non-trainable params: 7039552 (26.85 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Add the pre-trained DenseNet121_base \n",
    "model.add(DenseNet121_base)\n",
    "\n",
    "# Batch Normalization\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#Dropout \n",
    "model.add(Dropout(0.35))\n",
    "\n",
    "# Add a dense layer with 120 units and ReLU activation function\n",
    "model.add(Dense(220, activation='relu'))\n",
    "\n",
    "model.add(Dense(220, activation='relu'))\n",
    "\n",
    "model.add(Dense(220, activation='relu'))\n",
    "\n",
    "model.add(Dense(220, activation='relu'))\n",
    "\n",
    "model.add(Dense(220, activation='relu'))\n",
    "\n",
    "model.add(Dense(220, activation='relu'))\n",
    "\n",
    "model.add(Dense(220, activation='relu'))\n",
    "\n",
    "model.add(Dense(220, activation='relu'))\n",
    "\n",
    "model.add(Dense(220, activation='relu'))\n",
    "\n",
    "model.add(Dense(220, activation='relu'))\n",
    "\n",
    "model.add(Dense(220, activation='relu'))\n",
    "\n",
    "\n",
    "# Add the output layer with 1 unit and sigmoid activation function for binary classification\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\bvcha\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\bvcha\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "49/49 [==============================] - 479s 10s/step - loss: 1.8764 - accuracy: 0.3321 - val_loss: 1.7903 - val_accuracy: 0.4397\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 475s 10s/step - loss: 1.3318 - accuracy: 0.5249 - val_loss: 1.4217 - val_accuracy: 0.5481\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 496s 10s/step - loss: 1.0624 - accuracy: 0.6444 - val_loss: 1.2477 - val_accuracy: 0.6081\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 466s 10s/step - loss: 0.8440 - accuracy: 0.7241 - val_loss: 0.9622 - val_accuracy: 0.7131\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 431s 9s/step - loss: 0.7314 - accuracy: 0.7681 - val_loss: 0.7454 - val_accuracy: 0.7734\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 411s 8s/step - loss: 0.6155 - accuracy: 0.8005 - val_loss: 0.6973 - val_accuracy: 0.7864\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 372s 8s/step - loss: 0.5366 - accuracy: 0.8269 - val_loss: 0.6126 - val_accuracy: 0.8073\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 1970s 41s/step - loss: 0.5062 - accuracy: 0.8394 - val_loss: 0.5882 - val_accuracy: 0.8212\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 701s 14s/step - loss: 0.4499 - accuracy: 0.8548 - val_loss: 0.5367 - val_accuracy: 0.8388\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 392s 8s/step - loss: 0.4158 - accuracy: 0.8665 - val_loss: 0.5026 - val_accuracy: 0.8433\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    patience=10, \n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "# Train the model \n",
    "history = model.fit(train_ds,\n",
    "                    epochs=10,\n",
    "                    validation_data=validation_ds,\n",
    "                    callbacks=early_stopping)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
